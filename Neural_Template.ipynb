{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZSVshXdkV53I9mi1i6axoKlhqD9tGgPV",
      "authorship_tag": "ABX9TyOMdnEnPfHaH9pCcBikvlF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinaBaniasadAzad/DF-VO/blob/master/Neural_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y39hjzYlu6s",
        "outputId": "990f611e-56f1-4aa9-ef26-668022bd6164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/edward1997104/Neural-Template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX29tSr_oq2P",
        "outputId": "cc028b9a-06ce-4556-cd24-da2d59bb7cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Neural-Template'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 82 (delta 30), reused 50 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), 7.30 MiB | 12.39 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/Neural-Template'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcSrFz_vqWLl",
        "outputId": "dacfe2cb-917f-442c-bda8-b05d8117552a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Neural-Template\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = '/content/Neural-Template'"
      ],
      "metadata": {
        "id": "7fa_wm7_oq-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBYwRgATss89",
        "outputId": "708099f2-0f24-4ec9-ab21-172efdb14d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from torchdiffeq) (1.13.1+cu116)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from torchdiffeq) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->torchdiffeq) (4.4.0)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyMCubes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVHNKnwQtE9s",
        "outputId": "db2d6bc3-5fc2-44c5-9f3c-c439e553682a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyMCubes\n",
            "  Downloading PyMCubes-0.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.9/276.9 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from PyMCubes) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from PyMCubes) (1.21.6)\n",
            "Installing collected packages: PyMCubes\n",
            "Successfully installed PyMCubes-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the command to evaluate the autoencoder\n",
        "!python utils/mesh_visualization.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJzvmPClqDAh",
        "outputId": "3706c15c-b646-48f2-d19f-48e6097082b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"utils/mesh_visualization.py\", line 68, in <module>\n",
            "    samples = ImNetSamples(data_path=data_path,\n",
            "  File \"/content/Neural-Template/data/data.py\", line 113, in __init__\n",
            "    data_dict = h5py.File(data_path, 'r')\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py\", line 424, in __init__\n",
            "    fid = make_fid(name, mode, userblock_size,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py\", line 190, in make_fid\n",
            "    fid = h5f.open(name, flags, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 96, in h5py.h5f.open\n",
            "OSError: Unable to open file (unable to open file: name = './data/all_vox256_img/all_vox256_img_test.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the command to evaluate the single view reconstruction task\n",
        "!python utils/image_mesh_visualization.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA3epGfWqeWc",
        "outputId": "3cd61ce4-5145-4840-ea76-3d1f9151d2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"utils/image_mesh_visualization.py\", line 71, in <module>\n",
            "    spec.loader.exec_module(config)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 980, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1037, in get_data\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/Neural-Template/./pretrain/image_encoder/config.py'\n"
          ]
        }
      ]
    }
  ]
}